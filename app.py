"""
Aplicaci贸n de Streamlit para demostraci贸n interactiva del perceptr贸n simple.
"""
import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from app.perceptron import Perceptron

# Configuraci贸n de la p谩gina
st.set_page_config(
    page_title="Perceptr贸n Simple - IA",
    page_icon="",
    layout="wide"
)

# T铆tulo y descripci贸n
st.title("Perceptr贸n Simple - Demostraci贸n Interactiva")
st.markdown("""
Esta aplicaci贸n demuestra el funcionamiento de un perceptr贸n simple en problemas de clasificaci贸n binaria.
Puedes configurar los par谩metros iniciales y visualizar el proceso de entrenamiento.
""")

# Definici贸n de problemas predefinidos
PROBLEMS = {
    "AND": {
        "X": np.array([[0, 0], [0, 1], [1, 0], [1, 1]]),
        "y": np.array([0, 0, 0, 1]),
        "description": "Operaci贸n l贸gica AND: Solo es 1 cuando ambas entradas son 1"
    },
    "OR": {
        "X": np.array([[0, 0], [0, 1], [1, 0], [1, 1]]),
        "y": np.array([0, 1, 1, 1]),
        "description": "Operaci贸n l贸gica OR: Es 1 cuando al menos una entrada es 1"
    },
    "NAND": {
        "X": np.array([[0, 0], [0, 1], [1, 0], [1, 1]]),
        "y": np.array([1, 1, 1, 0]),
        "description": "Operaci贸n l贸gica NAND: Es 0 solo cuando ambas entradas son 1"
    },
    "XOR": {
        "X": np.array([[0, 0], [0, 1], [1, 0], [1, 1]]),
        "y": np.array([0, 1, 1, 0]),
        "description": "Operaci贸n l贸gica XOR: Es 1 cuando las entradas son diferentes (no linealmente separable)"
    },
    "Personalizado": {
        "X": None,
        "y": None,
        "description": "Define tu propio problema de clasificaci贸n binaria"
    }
}

# Funci贸n para mostrar tablas de datos
def show_data_table(X, y):
    data = pd.DataFrame(X, columns=[f"X{i+1}" for i in range(X.shape[1])])
    data["y"] = y
    st.write("Datos de entrenamiento:")
    st.dataframe(data)

# Funci贸n para mostrar resultados de entrenamiento
def show_training_results(perceptron, epochs, error_history):
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Evoluci贸n de Pesos")
        weights_df = pd.DataFrame(perceptron.weights_history)
        weights_df.columns = [f"w{i+1}" for i in range(weights_df.shape[1])]
        weights_df["bias"] = [perceptron.bias] + [perceptron.bias] * epochs
        weights_df.index.name = "poca"
        st.dataframe(weights_df)
    
    with col2:
        st.subheader("Curva de Error")
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.plot(range(len(error_history)), error_history, marker='o')
        ax.set_xlabel("poca")
        ax.set_ylabel("Tasa de Error")
        ax.set_title("Evoluci贸n del Error Durante el Entrenamiento")
        ax.grid(True)
        st.pyplot(fig)
    
    # Mostrar frontera de decisi贸n si tenemos 2 dimensiones
    if perceptron.weights.shape[0] == 2:
        st.subheader("Frontera de Decisi贸n")
        decision_boundary = perceptron.plot_decision_boundary(
            PROBLEMS[selected_problem]["X"],
            PROBLEMS[selected_problem]["y"]
        )
        st.pyplot(decision_boundary)

# Panel lateral para configuraci贸n
st.sidebar.header("Configuraci贸n del Perceptr贸n")

# Selecci贸n del problema
selected_problem = st.sidebar.selectbox(
    "Selecciona un problema:",
    list(PROBLEMS.keys())
)

# Mostrar descripci贸n del problema
st.sidebar.markdown(f"**{PROBLEMS[selected_problem]['description']}**")

# Si se selecciona un problema predefinido, mostrar los datos
if selected_problem != "Personalizado":
    X = PROBLEMS[selected_problem]["X"]
    y = PROBLEMS[selected_problem]["y"]
    show_data_table(X, y)
else:
    st.warning("La opci贸n de problema personalizado est谩 en desarrollo. Por favor, selecciona uno predefinido.")
    st.stop()

# Configuraci贸n de par谩metros
st.sidebar.subheader("Par谩metros")

# N煤mero de caracter铆sticas
n_features = X.shape[1]

# Pesos iniciales
st.sidebar.markdown("**Pesos iniciales**")
weights = []
for i in range(n_features):
    weights.append(st.sidebar.number_input(f"Peso w{i+1}", value=0.0, step=0.1, format="%.2f"))

# Bias (umbral)
bias = st.sidebar.number_input("Bias (umbral)", value=0.0, step=0.1, format="%.2f")

# Tasa de aprendizaje
learning_rate = st.sidebar.slider("Tasa de aprendizaje (畏)", min_value=0.01, max_value=1.0, value=0.1, step=0.01)

# M谩ximo de 茅pocas
max_epochs = st.sidebar.slider("M谩ximo de 茅pocas", min_value=10, max_value=1000, value=100, step=10)

# Bot贸n para inicializar pesos aleatorios
if st.sidebar.button("Randomizar Pesos"):
    weights = np.random.randn(n_features)
    bias = np.random.randn()
    st.sidebar.success("隆Pesos inicializados aleatoriamente!")
    st.rerun()

# Bot贸n para entrenar el perceptr贸n
if st.sidebar.button("Entrenar Perceptr贸n"):
    # Crear y entrenar el perceptr贸n
    perceptron = Perceptron(
        input_size=n_features,
        weights=np.array(weights),
        bias=bias,
        learning_rate=learning_rate,
        max_epochs=max_epochs
    )
    
    with st.spinner("Entrenando perceptr贸n..."):
        error_history, epochs = perceptron.fit(X, y)
    
    # Mostrar mensaje de convergencia
    if error_history[-1] == 0:
        st.success(f"隆El perceptr贸n ha convergido en {epochs} 茅pocas!")
    else:
        st.warning(f"El perceptr贸n no convergi贸 despu茅s de {epochs} 茅pocas. Error final: {error_history[-1]:.4f}")
    
    # Mostrar resultados
    show_training_results(perceptron, epochs, error_history)
    
    # Mostrar predicciones
    st.subheader("Predicciones finales")
    predictions = perceptron.predict(X)
    pred_df = pd.DataFrame({
        "Esperado": y,
        "Predicci贸n": predictions,
        "驴Correcto?": y == predictions
    })
    st.dataframe(pred_df)

# Informaci贸n adicional
st.sidebar.markdown("---")
st.sidebar.info("""
**Informaci贸n:**
- El perceptr贸n se detendr谩 cuando el error sea 0 o se alcance el m谩ximo de 茅pocas.
- Para problemas no linealmente separables (como XOR), el perceptr贸n no converger谩.
""") 